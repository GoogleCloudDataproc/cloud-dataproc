# Spark and Jupyter Notebooks on Dataproc

[Google Cloud Dataproc](https://cloud.google.com/dataproc) allows you to use [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) or [Classic Jupyter Notebooks](https://jupyter-notebook.readthedocs.io/en/stable/) on your cluster by enabling the [Jupyter component](https://cloud.google.com/dataproc/docs/concepts/components/jupyter) and [Component Gateway](https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways). 

This folder contains example notebooks for using Spark with the [BigQuery Storage connector](https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery) and [Google Cloud Storage connector](https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage), and other common use cases.

### Create Dataproc Cluster with Jupyter

These notebooks are designed to be run on Google Cloud Dataproc.

Follow the links below for instructions on how to create a Dataproc Cluster with the Juypter component installed.

* [Tutorial - Install and run a Jupyter notebook on a Dataproc cluster](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)
* [Blog post - Apache Spark and Jupyter Notebooks made easy with Dataproc component gateway](https://medium.com/google-cloud/apache-spark-and-jupyter-notebooks-made-easy-with-dataproc-component-gateway-fa91d48d6a5a)

## Notebooks

### Python 3 Kernel (PySpark)

* 1.1. BigQuery Storage & Spark DataFrames
* 1.2. BigQuery Storage & Spark SQL
* 1.3. BigQuery Storage & Spark MLlib
* 2.1. Google Cloud Storage (CSV) & Spark DataFrames
* 3.1. Spark DataFrames & Pandas Plotting


