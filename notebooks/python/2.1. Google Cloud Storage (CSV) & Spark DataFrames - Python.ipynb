{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Google Cloud Storage (CSV) & Spark DataFrames - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataproc Cluster with Jupyter\n",
    "\n",
    "This notebook is designed to be run on Google Cloud Dataproc.\n",
    "\n",
    "Follow the links below for instructions on how to create a Dataproc Cluster with the Juypter component installed.\n",
    "\n",
    "* [Tutorial - Install and run a Jupyter notebook on a Dataproc cluster](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)\n",
    "* [Blog post - Apache Spark and Jupyter Notebooks made easy with Dataproc component gateway](https://medium.com/google-cloud/apache-spark-and-jupyter-notebooks-made-easy-with-dataproc-component-gateway-fa91d48d6a5a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 3 Kernel\n",
    "\n",
    "Use a Python 3 kernel (not PySpark) to allow you to configure the SparkSession in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('2.1. Google Cloud Storage (CSV) & Spark DataFrames') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable repl.eagerEval\n",
    "\n",
    "This will output the results of DataFrames in each step without the need to use `df.show()` and also improves the formatting of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files in a GCS bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List files in a Google Cloud Storage bucket using the [google-cloud-storage python library](https://googleapis.dev/python/storage/latest/client.html) which comes installed on Dataproc clusters. We will be using a publicly available dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: solutions-public-assets, time-series-master/, 1423455996970000>,\n",
       " <Blob: solutions-public-assets, time-series-master/GBPUSD_2014_01.csv, 1423456343320000>,\n",
       " <Blob: solutions-public-assets, time-series-master/GBPUSD_2014_02.csv, 1423456332787000>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket('solutions-public-assets')\n",
    "\n",
    "list(bucket.list_blobs(prefix='time-series-master/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively use the hdfs cmd to list files in a directory which supports GCS buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rwx------   3 root root   67868938 2015-02-09 04:32 gs://solutions-public-assets/time-series-master/GBPUSD_2014_01.csv\n",
      "-rwx------   3 root root   61275261 2015-02-09 04:32 gs://solutions-public-assets/time-series-master/GBPUSD_2014_02.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls 'gs://solutions-public-assets/time-series-master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV files from GCS into Spark Dataframe\n",
    "\n",
    "Read CSV files from GCS into a dataframe and infer the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- XYZ: string (nullable = true)\n",
      " |-- GBP/USD: string (nullable = true)\n",
      " |-- 2014-01-01 00:00:00.000000: timestamp (nullable = true)\n",
      " |-- 1.4995: double (nullable = true)\n",
      " |-- 1.5005: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark \\\n",
    "  .read \\\n",
    "  .option ( \"inferSchema\" , \"true\" ) \\\n",
    "  .option ( \"header\" , \"true\" ) \\\n",
    "  .csv ( \"gs://solutions-public-assets/time-series-master/GBPUSD_*.csv\" )\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>XYZ</th><th>GBP/USD</th><th>2014-01-01 00:00:00.000000</th><th>1.4995</th><th>1.5005</th></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.498</td><td>1.499</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+-------+--------------------------+------+------+\n",
       "|XYZ|GBP/USD|2014-01-01 00:00:00.000000|1.4995|1.5005|\n",
       "+---+-------+--------------------------+------+------+\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4988|1.4998|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4993|1.5003|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4989|1.4999|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4998|1.5008|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.5001|1.5011|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4991|1.5001|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4978|1.4988|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4974|1.4984|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4987|1.4997|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4991|1.5001|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4997|1.5007|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4996|1.5006|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4998|1.5008|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4995|1.5005|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4992|1.5002|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4979|1.4989|\n",
       "|XYZ|GBP/USD|      2014-01-01 00:01:...| 1.498| 1.499|\n",
       "+---+-------+--------------------------+------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no header with column names as we can see with the dataset here or the schema is not infered correctly then read CSV files from GCS and define schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- venue: string (nullable = true)\n",
      " |-- currencies: string (nullable = true)\n",
      " |-- time_stamp: timestamp (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- ask: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, TimestampType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"venue\", StringType()),\n",
    "    StructField(\"currencies\", StringType()),\n",
    "    StructField(\"time_stamp\", TimestampType()),\n",
    "    StructField(\"bid\", DoubleType()),\n",
    "    StructField(\"ask\", DoubleType())\n",
    "])\n",
    "\n",
    "df2 = spark \\\n",
    "  .read \\\n",
    "  .schema(schema) \\\n",
    "  .csv ( \"gs://solutions-public-assets/time-series-master/GBPUSD_*.csv\" )\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the top 20 rows of the spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>venue</th><th>currencies</th><th>time_stamp</th><th>bid</th><th>ask</th></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:00</td><td>1.4995</td><td>1.5005</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----+----------+--------------------+------+------+\n",
       "|venue|currencies|          time_stamp|   bid|   ask|\n",
       "+-----+----------+--------------------+------+------+\n",
       "|  XYZ|   GBP/USD| 2014-01-01 00:00:00|1.4995|1.5005|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4988|1.4998|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4993|1.5003|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4989|1.4999|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4998|1.5008|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.5001|1.5011|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4991|1.5001|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4978|1.4988|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4974|1.4984|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4987|1.4997|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4991|1.5001|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4997|1.5007|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4996|1.5006|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4998|1.5008|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4995|1.5005|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4992|1.5002|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4979|1.4989|\n",
       "+-----+----------+--------------------+------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the dataframe. No of rows and no of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2436683, 5)\n"
     ]
    }
   ],
   "source": [
    "print((df2.count(), len(df2.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add hour column and filter the data to create a new dataframe with only 1 day of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>venue</th><th>currencies</th><th>time_stamp</th><th>bid</th><th>ask</th><th>hour</th></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:00</td><td>1.4995</td><td>1.5005</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td><td>0</td></tr>\n",
       "<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----+----------+--------------------+------+------+----+\n",
       "|venue|currencies|          time_stamp|   bid|   ask|hour|\n",
       "+-----+----------+--------------------+------+------+----+\n",
       "|  XYZ|   GBP/USD| 2014-01-01 00:00:00|1.4995|1.5005|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4988|1.4998|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4993|1.5003|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4989|1.4999|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4998|1.5008|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.5001|1.5011|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4991|1.5001|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4978|1.4988|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4974|1.4984|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4987|1.4997|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4991|1.5001|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4997|1.5007|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4996|1.5006|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4998|1.5008|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4995|1.5005|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4992|1.5002|   0|\n",
       "|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4979|1.4989|   0|\n",
       "+-----+----------+--------------------+------+------+----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df3 = df2.withColumn(\"hour\", F.hour(F.col(\"time_stamp\"))) \\\n",
    "  .filter(df2['time_stamp'] >= F.lit('2014-01-01 00:00:00')) \\\n",
    "  .filter(df2['time_stamp'] < F.lit('2014-01-02 00:00:10')).cache()\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41390, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df3.count(), len(df3.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by hour and order by top_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>hour</th><th>total_bids</th></tr>\n",
       "<tr><td>12</td><td>4888.966399999975</td></tr>\n",
       "<tr><td>13</td><td>4852.239699999989</td></tr>\n",
       "<tr><td>14</td><td>4569.660199999988</td></tr>\n",
       "<tr><td>15</td><td>4518.744800000002</td></tr>\n",
       "<tr><td>8</td><td>2489.1048999999966</td></tr>\n",
       "<tr><td>10</td><td>2431.1414000000077</td></tr>\n",
       "<tr><td>9</td><td>2424.1796000000018</td></tr>\n",
       "<tr><td>18</td><td>2368.89479999999</td></tr>\n",
       "<tr><td>19</td><td>2355.5363999999986</td></tr>\n",
       "<tr><td>11</td><td>2347.3602999999907</td></tr>\n",
       "<tr><td>17</td><td>2300.944100000002</td></tr>\n",
       "<tr><td>16</td><td>2295.8520999999996</td></tr>\n",
       "<tr><td>4</td><td>1749.3830000000016</td></tr>\n",
       "<tr><td>5</td><td>1726.0291000000027</td></tr>\n",
       "<tr><td>6</td><td>1662.2480999999957</td></tr>\n",
       "<tr><td>7</td><td>1648.9573000000023</td></tr>\n",
       "<tr><td>20</td><td>1572.7295999999976</td></tr>\n",
       "<tr><td>21</td><td>1558.4258999999997</td></tr>\n",
       "<tr><td>23</td><td>1546.2942000000016</td></tr>\n",
       "<tr><td>22</td><td>1512.3183999999997</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----+------------------+\n",
       "|hour|        total_bids|\n",
       "+----+------------------+\n",
       "|  12| 4888.966399999975|\n",
       "|  13| 4852.239699999989|\n",
       "|  14| 4569.660199999988|\n",
       "|  15| 4518.744800000002|\n",
       "|   8|2489.1048999999966|\n",
       "|  10|2431.1414000000077|\n",
       "|   9|2424.1796000000018|\n",
       "|  18|  2368.89479999999|\n",
       "|  19|2355.5363999999986|\n",
       "|  11|2347.3602999999907|\n",
       "|  17| 2300.944100000002|\n",
       "|  16|2295.8520999999996|\n",
       "|   4|1749.3830000000016|\n",
       "|   5|1726.0291000000027|\n",
       "|   6|1662.2480999999957|\n",
       "|   7|1648.9573000000023|\n",
       "|  20|1572.7295999999976|\n",
       "|  21|1558.4258999999997|\n",
       "|  23|1546.2942000000016|\n",
       "|  22|1512.3183999999997|\n",
       "+----+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df4 = df3 \\\n",
    ".groupBy(\"hour\") \\\n",
    ".agg(F.sum('bid').alias('total_bids'))\n",
    "\n",
    "df4.orderBy('total_bids', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Spark Dataframe to Google Cloud Storage in CSV format\n",
    "\n",
    "Write the Spark Dataframe to Google Cloud Storage using \n",
    "\n",
    "If the GCS bucket  does not exist it will need to be created before running `df.write`\n",
    "\n",
    "- [Instructions here for creating a GCS bucket](https://cloud.google.com/storage/docs/creating-buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to your GCS bucket\n",
    "gcs_bucket = 'dataproc-bucket-name'\n",
    "\n",
    "gcs_filepath = 'gs://{}/currency/hourly_bids.csv'.format(gcs_bucket)\n",
    "\n",
    "df4.coalesce(1).write \\\n",
    "  .mode('overwrite') \\\n",
    "  .csv(gcs_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file into new DataFrame to check it was successfuly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwx------   - root root          0 2020-03-27 17:08 gs://dataproc-bucket-name/currency/hourly_bids.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls gs://dataproc-bucket-name/currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>12</th><th>4888.966399999975</th></tr>\n",
       "<tr><td>22</td><td>1512.3183999999997</td></tr>\n",
       "<tr><td>1</td><td>1040.8376999999998</td></tr>\n",
       "<tr><td>13</td><td>4852.239699999989</td></tr>\n",
       "<tr><td>6</td><td>1662.2480999999957</td></tr>\n",
       "<tr><td>16</td><td>2295.8520999999996</td></tr>\n",
       "<tr><td>3</td><td>1032.2795000000003</td></tr>\n",
       "<tr><td>20</td><td>1572.7295999999976</td></tr>\n",
       "<tr><td>5</td><td>1726.0291000000027</td></tr>\n",
       "<tr><td>19</td><td>2355.5363999999986</td></tr>\n",
       "<tr><td>15</td><td>4518.744800000002</td></tr>\n",
       "<tr><td>9</td><td>2424.1796000000018</td></tr>\n",
       "<tr><td>17</td><td>2300.944100000002</td></tr>\n",
       "<tr><td>4</td><td>1749.3830000000016</td></tr>\n",
       "<tr><td>8</td><td>2489.1048999999966</td></tr>\n",
       "<tr><td>23</td><td>1546.2942000000016</td></tr>\n",
       "<tr><td>7</td><td>1648.9573000000023</td></tr>\n",
       "<tr><td>10</td><td>2431.1414000000077</td></tr>\n",
       "<tr><td>21</td><td>1558.4258999999997</td></tr>\n",
       "<tr><td>11</td><td>2347.3602999999907</td></tr>\n",
       "<tr><td>14</td><td>4569.660199999988</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+------------------+\n",
       "| 12| 4888.966399999975|\n",
       "+---+------------------+\n",
       "| 22|1512.3183999999997|\n",
       "|  1|1040.8376999999998|\n",
       "| 13| 4852.239699999989|\n",
       "|  6|1662.2480999999957|\n",
       "| 16|2295.8520999999996|\n",
       "|  3|1032.2795000000003|\n",
       "| 20|1572.7295999999976|\n",
       "|  5|1726.0291000000027|\n",
       "| 19|2355.5363999999986|\n",
       "| 15| 4518.744800000002|\n",
       "|  9|2424.1796000000018|\n",
       "| 17| 2300.944100000002|\n",
       "|  4|1749.3830000000016|\n",
       "|  8|2489.1048999999966|\n",
       "| 23|1546.2942000000016|\n",
       "|  7|1648.9573000000023|\n",
       "| 10|2431.1414000000077|\n",
       "| 21|1558.4258999999997|\n",
       "| 11|2347.3602999999907|\n",
       "| 14| 4569.660199999988|\n",
       "+---+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = spark.read \\\n",
    "  .option ( \"inferSchema\" , \"true\" ) \\\n",
    "  .option ( \"header\" , \"true\" ) \\\n",
    "  .csv('gs://dataproc-bucket-name/currency/*')\n",
    "\n",
    "df5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}