{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. BigQuery Storage & Spark ML - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 3 Kernel\n",
    "\n",
    "Use a Python 3 kernel (not PySpark) to allow you to configure the SparkSession in the notebook and include the [spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) required to use the [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scala Version\n",
    "\n",
    "Check what version of Scala you are running so you can include the correct spark-bigquery-connector jar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scala code runner version 2.12.10 -- Copyright 2002-2019, LAMP/EPFL and Lightbend, Inc.\n"
     ]
    }
   ],
   "source": [
    "!scala -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session\n",
    "\n",
    "Include the correct version of the spark-bigquery-connector jar\n",
    "\n",
    "If you are using scala version 2.11 use `'gs://spark-lib/bigquery/spark-bigquery-latest.jar'`.\n",
    "\n",
    "If you are using scala version 2.12 use `'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('BigQuery Storage &  Spark ML')\\\n",
    "  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from BigQuery as a Spark Dataframe.\n",
    "table  = 'bigquery-public-data.samples.natality'\n",
    "\n",
    "df_natality_table = spark.read \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"table\", table) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- weight_pounds: double (nullable = true)\n",
      " |-- mother_age: long (nullable = true)\n",
      " |-- father_age: long (nullable = true)\n",
      " |-- gestation_weeks: long (nullable = true)\n",
      " |-- weight_gain_pounds: long (nullable = true)\n",
      " |-- apgar_5min: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# limit no of rows that will be read for demo \n",
    "limit = 1000\n",
    "\n",
    "df_natality_select = df_natality_table \\\n",
    ".select(\"weight_pounds\", \"mother_age\", \"father_age\", \"gestation_weeks\", \"weight_gain_pounds\", \"apgar_5min\") \\\n",
    ".where(\"\"\"\n",
    "weight_pounds IS NOT NULL \n",
    "AND mother_age IS NOT NULL\n",
    "AND father_age IS NOT NULL\n",
    "AND gestation_weeks IS NOT NULL\n",
    "AND weight_gain_pounds IS NOT NULL\n",
    "AND apgar_5min IS NOT NULL\n",
    "\"\"\") \\\n",
    ".limit(limit) \\\n",
    ".cache()\n",
    "\n",
    "df_natality_select.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_natality_select.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view so that Spark SQL queries can be run against the data.\n",
    "df_natality_select.createOrReplaceTempView(\"natality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- weight_pounds: double (nullable = true)\n",
      " |-- mother_age: long (nullable = true)\n",
      " |-- father_age: long (nullable = true)\n",
      " |-- gestation_weeks: long (nullable = true)\n",
      " |-- weight_gain_pounds: long (nullable = true)\n",
      " |-- apgar_5min: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional\n",
    "# As a precaution, run a query in Spark SQL to ensure no NULL values exist.\n",
    "spark_sql_query = \"\"\"\n",
    "SELECT *\n",
    "from natality\n",
    "where weight_pounds is not null\n",
    "and mother_age is not null\n",
    "and father_age is not null\n",
    "and gestation_weeks is not null\n",
    "\"\"\"\n",
    "\n",
    "df_natality_select = spark.sql(spark_sql_query).cache()\n",
    "df_natality_select.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
      "|     weight_pounds|mother_age|father_age|gestation_weeks|weight_gain_pounds|apgar_5min|            features|\n",
      "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
      "|     8.62889293468|        34|        38|             41|                57|         9|[34.0,38.0,41.0,5...|\n",
      "|      2.6786164833|        36|        39|             34|                23|         6|[36.0,39.0,34.0,2...|\n",
      "|    11.06279630716|        38|        41|             41|                11|         9|[38.0,41.0,41.0,1...|\n",
      "|     5.43659938092|        42|        42|             38|                10|         9|[42.0,42.0,38.0,1...|\n",
      "|3.5604655312999998|        38|        43|             31|                18|         8|[38.0,43.0,31.0,1...|\n",
      "|     5.99877814902|        37|        42|             39|                20|         9|[37.0,42.0,39.0,2...|\n",
      "|     9.18666245754|        28|        36|             38|                37|         8|[28.0,36.0,38.0,3...|\n",
      "|     4.87442061282|        26|        27|             36|                17|         9|[26.0,27.0,36.0,1...|\n",
      "| 8.000575487979999|        36|        39|             40|                13|         9|[36.0,39.0,40.0,1...|\n",
      "|      6.5256829552|        33|        34|             39|                99|        99|[33.0,34.0,39.0,9...|\n",
      "|      6.5697754076|        39|        37|             37|                99|        99|[39.0,37.0,37.0,9...|\n",
      "|      7.6610636045|        25|        31|             41|                99|        99|[25.0,31.0,41.0,9...|\n",
      "|     5.43659938092|        29|        35|             33|                99|        99|[29.0,35.0,33.0,9...|\n",
      "|     8.50102482272|        40|        61|             40|                99|        99|[40.0,61.0,40.0,9...|\n",
      "| 8.375361333379999|        39|        40|             39|                69|         9|[39.0,40.0,39.0,6...|\n",
      "|     4.87442061282|        29|        34|             34|                45|         9|[29.0,34.0,34.0,4...|\n",
      "|     5.00008410216|        36|        39|             33|                32|         8|[36.0,39.0,33.0,3...|\n",
      "| 8.811876612139999|        41|        99|             40|                18|         8|[41.0,99.0,40.0,1...|\n",
      "|     8.24969784404|        35|        39|             39|                16|        99|[35.0,39.0,39.0,1...|\n",
      "|      6.8122838958|        33|        40|             38|                10|        99|[33.0,40.0,38.0,1...|\n",
      "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an input DataFrame for Spark ML using VectorAssembler.\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"mother_age\", \"father_age\", \"gestation_weeks\", \"weight_gain_pounds\", \"apgar_5min\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(df_natality_select)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|             label|\n",
      "+--------------------+------------------+\n",
      "|[34.0,38.0,41.0,5...|     8.62889293468|\n",
      "|[36.0,39.0,34.0,2...|      2.6786164833|\n",
      "|[38.0,41.0,41.0,1...|    11.06279630716|\n",
      "|[42.0,42.0,38.0,1...|     5.43659938092|\n",
      "|[38.0,43.0,31.0,1...|3.5604655312999998|\n",
      "|[37.0,42.0,39.0,2...|     5.99877814902|\n",
      "|[28.0,36.0,38.0,3...|     9.18666245754|\n",
      "|[26.0,27.0,36.0,1...|     4.87442061282|\n",
      "|[36.0,39.0,40.0,1...| 8.000575487979999|\n",
      "|[33.0,34.0,39.0,9...|      6.5256829552|\n",
      "|[39.0,37.0,37.0,9...|      6.5697754076|\n",
      "|[25.0,31.0,41.0,9...|      7.6610636045|\n",
      "|[29.0,35.0,33.0,9...|     5.43659938092|\n",
      "|[40.0,61.0,40.0,9...|     8.50102482272|\n",
      "|[39.0,40.0,39.0,6...| 8.375361333379999|\n",
      "|[29.0,34.0,34.0,4...|     4.87442061282|\n",
      "|[36.0,39.0,33.0,3...|     5.00008410216|\n",
      "|[41.0,99.0,40.0,1...| 8.811876612139999|\n",
      "|[35.0,39.0,39.0,1...|     8.24969784404|\n",
      "|[33.0,40.0,38.0,1...|      6.8122838958|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = output.select(\"features\", \"weight_pounds\").withColumnRenamed(\"weight_pounds\",\"label\")\n",
    "training_data.cache()\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:[0.032105804524621015,-0.005448902107015991,0.20940221495235767,0.001514042532387989,0.0018310820530353473]\n",
      "Intercept:-1.565575404366004\n",
      "R^2:0.24565216749816365\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| 0.6216582894053992|\n",
      "| -3.864594671990025|\n",
      "| 3.0131311065978093|\n",
      "|-2.1063194482441983|\n",
      "| -2.393046931198261|\n",
      "|-1.6081542977973298|\n",
      "|  2.021483412756962|\n",
      "|-1.8283327433775005|\n",
      "| 0.2105982221406011|\n",
      "| -1.280824235206806|\n",
      "|-0.9942154737287696|\n",
      "|-0.3237482859356007|\n",
      "|-0.9796223995671598|\n",
      "|0.40749514257792185|\n",
      "| 0.6191313892123835|\n",
      "|   -1.5100966032044|\n",
      "|-1.3510133850752313|\n",
      "| 1.1825653194895507|\n",
      "| 0.5318890853072356|\n",
      "|-0.6173778816298201|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a new LinearRegression object and fit the training data.\n",
    "lr = LinearRegression(maxIter=5, regParam=0.2, solver=\"normal\")\n",
    "model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:[0.032105804524621015,-0.005448902107015991,0.20940221495235767,0.001514042532387989,0.0018310820530353473]\n",
      "Intercept:-1.565575404366004\n",
      "R^2:0.24565216749816365\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| 0.6216582894053992|\n",
      "| -3.864594671990025|\n",
      "| 3.0131311065978093|\n",
      "|-2.1063194482441983|\n",
      "| -2.393046931198261|\n",
      "|-1.6081542977973298|\n",
      "|  2.021483412756962|\n",
      "|-1.8283327433775005|\n",
      "| 0.2105982221406011|\n",
      "| -1.280824235206806|\n",
      "|-0.9942154737287696|\n",
      "|-0.3237482859356007|\n",
      "|-0.9796223995671598|\n",
      "|0.40749514257792185|\n",
      "| 0.6191313892123835|\n",
      "|   -1.5100966032044|\n",
      "|-1.3510133850752313|\n",
      "| 1.1825653194895507|\n",
      "| 0.5318890853072356|\n",
      "|-0.6173778816298201|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary.\n",
    "print(\"Coefficients:\" + str(model.coefficients))\n",
    "print(\"Intercept:\" + str(model.intercept))\n",
    "print(\"R^2:\" + str(model.summary.r2))\n",
    "model.summary.residuals.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}