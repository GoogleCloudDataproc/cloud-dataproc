{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. BigQuery Storage & Spark MLlib - Python\n",
    "\n",
    "Use the BigQuery storage connector and [Spark MLlib](https://spark.apache.org/docs/latest/ml-guide.html) to build a Linear Regression model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataproc Cluster with Jupyter\n",
    "\n",
    "This notebook is designed to be run on Google Cloud Dataproc.\n",
    "\n",
    "Follow the links below for instructions on how to create a Dataproc Cluster with the Juypter component installed.\n",
    "\n",
    "* [Tutorial - Install and run a Jupyter notebook on a Dataproc cluster](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)\n",
    "* [Blog post - Apache Spark and Jupyter Notebooks made easy with Dataproc component gateway](https://medium.com/google-cloud/apache-spark-and-jupyter-notebooks-made-easy-with-dataproc-component-gateway-fa91d48d6a5a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 3 Kernel\n",
    "\n",
    "Use a Python 3 kernel (not PySpark) to allow you to configure the SparkSession in the notebook and include the [spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) required to use the [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scala Version\n",
    "\n",
    "Check what version of Scala you are running so you can include the correct spark-bigquery-connector jar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /release: No such file or directory\n",
      "Scala code runner version 2.11.12 -- Copyright 2002-2017, LAMP/EPFL\n"
     ]
    }
   ],
   "source": [
    "!scala -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session\n",
    "\n",
    "Include the correct version of the spark-bigquery-connector jar\n",
    "\n",
    "If you are using scala version 2.11 use `'gs://spark-lib/bigquery/spark-bigquery-latest.jar'`.\n",
    "\n",
    "If you are using scala version 2.12 use `'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('1.3. BigQuery Storage &  Spark MLlib - Python')\\\n",
    "  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest.jar') \\\n",
    "  .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable repl.eagerEval\n",
    "\n",
    "This will output the results of DataFrames in each step without the new need to show `df.show()` and also improves the formatting of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from BigQuery as a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table  = 'bigquery-public-data.samples.natality'\n",
    "\n",
    "df_natality_table = spark.read \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"table\", table) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit no of rows and cache data\n",
    "\n",
    "limit the no of rows that will be read for this example to run faster. \n",
    "\n",
    "The DataFrame is cached as LinearRegression is iterative and this avoids re-reading the data from BigQuery Storage for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- weight_pounds: double (nullable = true)\n",
      " |-- mother_age: long (nullable = true)\n",
      " |-- father_age: long (nullable = true)\n",
      " |-- gestation_weeks: long (nullable = true)\n",
      " |-- weight_gain_pounds: long (nullable = true)\n",
      " |-- apgar_5min: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limit = 10000\n",
    "\n",
    "df_natality_select = df_natality_table \\\n",
    ".select(\"weight_pounds\", \"mother_age\", \"father_age\", \"gestation_weeks\", \"weight_gain_pounds\", \"apgar_5min\") \\\n",
    ".where(\"\"\"\n",
    "weight_pounds IS NOT NULL \n",
    "AND mother_age IS NOT NULL\n",
    "AND father_age IS NOT NULL\n",
    "AND gestation_weeks IS NOT NULL\n",
    "AND weight_gain_pounds IS NOT NULL\n",
    "AND apgar_5min IS NOT NULL\n",
    "\"\"\") \\\n",
    ".limit(limit) \\\n",
    ".cache()\n",
    "\n",
    "df_natality_select.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional \n",
    "#### Run count to check no of rows in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_natality_select.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an input DataFrame for Spark MLlib using VectorAssembler\n",
    "\n",
    "Spark MLlib estimators expect a single vector column for features. Multiple columns can be converted to a single vector column using [VectorAssembler](https://spark.apache.org/docs/latest/ml-features#vectorassembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>weight_pounds</th><th>mother_age</th><th>father_age</th><th>gestation_weeks</th><th>weight_gain_pounds</th><th>apgar_5min</th><th>features</th></tr>\n",
       "<tr><td>6.3713593718</td><td>31</td><td>34</td><td>37</td><td>30</td><td>9</td><td>[31.0,34.0,37.0,3...</td></tr>\n",
       "<tr><td>6.393405598</td><td>36</td><td>35</td><td>38</td><td>99</td><td>9</td><td>[36.0,35.0,38.0,9...</td></tr>\n",
       "<tr><td>6.21262654316</td><td>34</td><td>34</td><td>37</td><td>56</td><td>9</td><td>[34.0,34.0,37.0,5...</td></tr>\n",
       "<tr><td>9.67608867918</td><td>31</td><td>49</td><td>37</td><td>99</td><td>8</td><td>[31.0,49.0,37.0,9...</td></tr>\n",
       "<tr><td>6.3382900325</td><td>43</td><td>47</td><td>34</td><td>18</td><td>9</td><td>[43.0,47.0,34.0,1...</td></tr>\n",
       "<tr><td>7.3193470984</td><td>43</td><td>46</td><td>44</td><td>99</td><td>99</td><td>[43.0,46.0,44.0,9...</td></tr>\n",
       "<tr><td>7.06140625186</td><td>29</td><td>30</td><td>40</td><td>99</td><td>99</td><td>[29.0,30.0,40.0,9...</td></tr>\n",
       "<tr><td>6.20821729792</td><td>35</td><td>34</td><td>39</td><td>99</td><td>99</td><td>[35.0,34.0,39.0,9...</td></tr>\n",
       "<tr><td>7.8484565272</td><td>39</td><td>45</td><td>40</td><td>23</td><td>10</td><td>[39.0,45.0,40.0,2...</td></tr>\n",
       "<tr><td>5.8312268299</td><td>41</td><td>43</td><td>38</td><td>35</td><td>9</td><td>[41.0,43.0,38.0,3...</td></tr>\n",
       "<tr><td>8.12623897732</td><td>42</td><td>45</td><td>39</td><td>14</td><td>10</td><td>[42.0,45.0,39.0,1...</td></tr>\n",
       "<tr><td>7.87491199864</td><td>41</td><td>42</td><td>38</td><td>30</td><td>9</td><td>[41.0,42.0,38.0,3...</td></tr>\n",
       "<tr><td>9.06320359082</td><td>33</td><td>37</td><td>38</td><td>39</td><td>9</td><td>[33.0,37.0,38.0,3...</td></tr>\n",
       "<tr><td>7.25100379718</td><td>33</td><td>30</td><td>36</td><td>11</td><td>9</td><td>[33.0,30.0,36.0,1...</td></tr>\n",
       "<tr><td>6.4374980503999994</td><td>30</td><td>33</td><td>39</td><td>99</td><td>9</td><td>[30.0,33.0,39.0,9...</td></tr>\n",
       "<tr><td>9.2153225516</td><td>39</td><td>41</td><td>38</td><td>17</td><td>9</td><td>[39.0,41.0,38.0,1...</td></tr>\n",
       "<tr><td>7.3744626639</td><td>31</td><td>99</td><td>41</td><td>20</td><td>9</td><td>[31.0,99.0,41.0,2...</td></tr>\n",
       "<tr><td>5.74965579296</td><td>35</td><td>40</td><td>30</td><td>33</td><td>8</td><td>[35.0,40.0,30.0,3...</td></tr>\n",
       "<tr><td>4.4423145793</td><td>43</td><td>47</td><td>37</td><td>30</td><td>8</td><td>[43.0,47.0,37.0,3...</td></tr>\n",
       "<tr><td>3.7258122278</td><td>37</td><td>44</td><td>33</td><td>1</td><td>9</td><td>[37.0,44.0,33.0,1...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
       "|     weight_pounds|mother_age|father_age|gestation_weeks|weight_gain_pounds|apgar_5min|            features|\n",
       "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
       "|      6.3713593718|        31|        34|             37|                30|         9|[31.0,34.0,37.0,3...|\n",
       "|       6.393405598|        36|        35|             38|                99|         9|[36.0,35.0,38.0,9...|\n",
       "|     6.21262654316|        34|        34|             37|                56|         9|[34.0,34.0,37.0,5...|\n",
       "|     9.67608867918|        31|        49|             37|                99|         8|[31.0,49.0,37.0,9...|\n",
       "|      6.3382900325|        43|        47|             34|                18|         9|[43.0,47.0,34.0,1...|\n",
       "|      7.3193470984|        43|        46|             44|                99|        99|[43.0,46.0,44.0,9...|\n",
       "|     7.06140625186|        29|        30|             40|                99|        99|[29.0,30.0,40.0,9...|\n",
       "|     6.20821729792|        35|        34|             39|                99|        99|[35.0,34.0,39.0,9...|\n",
       "|      7.8484565272|        39|        45|             40|                23|        10|[39.0,45.0,40.0,2...|\n",
       "|      5.8312268299|        41|        43|             38|                35|         9|[41.0,43.0,38.0,3...|\n",
       "|     8.12623897732|        42|        45|             39|                14|        10|[42.0,45.0,39.0,1...|\n",
       "|     7.87491199864|        41|        42|             38|                30|         9|[41.0,42.0,38.0,3...|\n",
       "|     9.06320359082|        33|        37|             38|                39|         9|[33.0,37.0,38.0,3...|\n",
       "|     7.25100379718|        33|        30|             36|                11|         9|[33.0,30.0,36.0,1...|\n",
       "|6.4374980503999994|        30|        33|             39|                99|         9|[30.0,33.0,39.0,9...|\n",
       "|      9.2153225516|        39|        41|             38|                17|         9|[39.0,41.0,38.0,1...|\n",
       "|      7.3744626639|        31|        99|             41|                20|         9|[31.0,99.0,41.0,2...|\n",
       "|     5.74965579296|        35|        40|             30|                33|         8|[35.0,40.0,30.0,3...|\n",
       "|      4.4423145793|        43|        47|             37|                30|         8|[43.0,47.0,37.0,3...|\n",
       "|      3.7258122278|        37|        44|             33|                 1|         9|[37.0,44.0,33.0,1...|\n",
       "+------------------+----------+----------+---------------+------------------+----------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"mother_age\", \"father_age\", \"gestation_weeks\", \"weight_gain_pounds\", \"apgar_5min\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "df_assembler_output = assembler.transform(df_natality_select)\n",
    "df_assembler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training data DataFrame\n",
    "\n",
    "Create a training data DataFrame with just the features and label column.\n",
    "\n",
    "Cache the training data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th></tr>\n",
       "<tr><td>[31.0,34.0,37.0,3...</td><td>6.3713593718</td></tr>\n",
       "<tr><td>[36.0,35.0,38.0,9...</td><td>6.393405598</td></tr>\n",
       "<tr><td>[34.0,34.0,37.0,5...</td><td>6.21262654316</td></tr>\n",
       "<tr><td>[31.0,49.0,37.0,9...</td><td>9.67608867918</td></tr>\n",
       "<tr><td>[43.0,47.0,34.0,1...</td><td>6.3382900325</td></tr>\n",
       "<tr><td>[43.0,46.0,44.0,9...</td><td>7.3193470984</td></tr>\n",
       "<tr><td>[29.0,30.0,40.0,9...</td><td>7.06140625186</td></tr>\n",
       "<tr><td>[35.0,34.0,39.0,9...</td><td>6.20821729792</td></tr>\n",
       "<tr><td>[39.0,45.0,40.0,2...</td><td>7.8484565272</td></tr>\n",
       "<tr><td>[41.0,43.0,38.0,3...</td><td>5.8312268299</td></tr>\n",
       "<tr><td>[42.0,45.0,39.0,1...</td><td>8.12623897732</td></tr>\n",
       "<tr><td>[41.0,42.0,38.0,3...</td><td>7.87491199864</td></tr>\n",
       "<tr><td>[33.0,37.0,38.0,3...</td><td>9.06320359082</td></tr>\n",
       "<tr><td>[33.0,30.0,36.0,1...</td><td>7.25100379718</td></tr>\n",
       "<tr><td>[30.0,33.0,39.0,9...</td><td>6.4374980503999994</td></tr>\n",
       "<tr><td>[39.0,41.0,38.0,1...</td><td>9.2153225516</td></tr>\n",
       "<tr><td>[31.0,99.0,41.0,2...</td><td>7.3744626639</td></tr>\n",
       "<tr><td>[35.0,40.0,30.0,3...</td><td>5.74965579296</td></tr>\n",
       "<tr><td>[43.0,47.0,37.0,3...</td><td>4.4423145793</td></tr>\n",
       "<tr><td>[37.0,44.0,33.0,1...</td><td>3.7258122278</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+------------------+\n",
       "|            features|             label|\n",
       "+--------------------+------------------+\n",
       "|[31.0,34.0,37.0,3...|      6.3713593718|\n",
       "|[36.0,35.0,38.0,9...|       6.393405598|\n",
       "|[34.0,34.0,37.0,5...|     6.21262654316|\n",
       "|[31.0,49.0,37.0,9...|     9.67608867918|\n",
       "|[43.0,47.0,34.0,1...|      6.3382900325|\n",
       "|[43.0,46.0,44.0,9...|      7.3193470984|\n",
       "|[29.0,30.0,40.0,9...|     7.06140625186|\n",
       "|[35.0,34.0,39.0,9...|     6.20821729792|\n",
       "|[39.0,45.0,40.0,2...|      7.8484565272|\n",
       "|[41.0,43.0,38.0,3...|      5.8312268299|\n",
       "|[42.0,45.0,39.0,1...|     8.12623897732|\n",
       "|[41.0,42.0,38.0,3...|     7.87491199864|\n",
       "|[33.0,37.0,38.0,3...|     9.06320359082|\n",
       "|[33.0,30.0,36.0,1...|     7.25100379718|\n",
       "|[30.0,33.0,39.0,9...|6.4374980503999994|\n",
       "|[39.0,41.0,38.0,1...|      9.2153225516|\n",
       "|[31.0,99.0,41.0,2...|      7.3744626639|\n",
       "|[35.0,40.0,30.0,3...|     5.74965579296|\n",
       "|[43.0,47.0,37.0,3...|      4.4423145793|\n",
       "|[37.0,44.0,33.0,1...|      3.7258122278|\n",
       "+--------------------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_data = df_assembler_output \\\n",
    ".select(\"features\", \"weight_pounds\") \\\n",
    ".withColumnRenamed(\"weight_pounds\",\"label\")\n",
    "\n",
    "df_training_data.cache()\n",
    "df_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets\n",
    "\n",
    "30% held out for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_training, df_test) = df_training_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a new LinearRegression object and fit the training data\n",
    "\n",
    "Import and use and the [LinearRegression model](https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=5, regParam=0.2, solver=\"normal\")\n",
    "\n",
    "model = lr.fit(df_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the coefficients and intercept for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:[0.024976900994897657,-0.00405761639159605,0.27142700913671225,-0.00020640385689556944,0.0008561742907835546]\n",
      "Intercept:-3.8299366375006008\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients:\" + str(model.coefficients))\n",
    "print(\"Intercept:\" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the model over the training data and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 1\n",
      "objectiveHistory: [0.0]\n",
      "RMSE: 1.205822\n",
      "r2: 0.391391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>residuals</th></tr>\n",
       "<tr><td>-0.06427120097813521</td></tr>\n",
       "<tr><td>1.4054942809910722</td></tr>\n",
       "<tr><td>1.615669149519861</td></tr>\n",
       "<tr><td>1.8461326439359498</td></tr>\n",
       "<tr><td>0.07032860053297885</td></tr>\n",
       "<tr><td>-1.43244194979542</td></tr>\n",
       "<tr><td>-1.7109598506752508</td></tr>\n",
       "<tr><td>2.995209709060892</td></tr>\n",
       "<tr><td>0.21341987241150395</td></tr>\n",
       "<tr><td>1.267985188300587</td></tr>\n",
       "<tr><td>1.029342775083852</td></tr>\n",
       "<tr><td>-0.724076824537927</td></tr>\n",
       "<tr><td>0.6977075173507492</td></tr>\n",
       "<tr><td>-0.10059277216248841</td></tr>\n",
       "<tr><td>-2.514989420406767</td></tr>\n",
       "<tr><td>0.4217857187789251</td></tr>\n",
       "<tr><td>-0.28999264665870594</td></tr>\n",
       "<tr><td>0.6565114778614269</td></tr>\n",
       "<tr><td>0.16326074403054758</td></tr>\n",
       "<tr><td>-0.09278719428170223</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|           residuals|\n",
       "+--------------------+\n",
       "|-0.06427120097813521|\n",
       "|  1.4054942809910722|\n",
       "|   1.615669149519861|\n",
       "|  1.8461326439359498|\n",
       "| 0.07032860053297885|\n",
       "|   -1.43244194979542|\n",
       "| -1.7109598506752508|\n",
       "|   2.995209709060892|\n",
       "| 0.21341987241150395|\n",
       "|   1.267985188300587|\n",
       "|   1.029342775083852|\n",
       "|  -0.724076824537927|\n",
       "|  0.6977075173507492|\n",
       "|-0.10059277216248841|\n",
       "|  -2.514989420406767|\n",
       "|  0.4217857187789251|\n",
       "|-0.28999264665870594|\n",
       "|  0.6565114778614269|\n",
       "| 0.16326074403054758|\n",
       "|-0.09278719428170223|\n",
       "+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSummary = model.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n",
    "\n",
    "trainingSummary.residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>prediction</th><th>label</th><th>features</th></tr>\n",
       "<tr><td>6.735331281174319</td><td>6.25671899556</td><td>[13.0,17.0,38.0,6...</td></tr>\n",
       "<tr><td>7.315888778823852</td><td>8.437090766739999</td><td>[14.0,16.0,40.0,1...</td></tr>\n",
       "<tr><td>7.372168136194236</td><td>7.50012615324</td><td>[14.0,17.0,40.0,9...</td></tr>\n",
       "<tr><td>6.7400855825755</td><td>5.37486994756</td><td>[14.0,20.0,38.0,9...</td></tr>\n",
       "<tr><td>5.682308546399798</td><td>5.8753192823</td><td>[14.0,99.0,35.0,9...</td></tr>\n",
       "<tr><td>4.33033463412318</td><td>3.0622208191799998</td><td>[15.0,18.0,29.0,9...</td></tr>\n",
       "<tr><td>7.134663854645244</td><td>9.06320359082</td><td>[15.0,18.0,39.0,3...</td></tr>\n",
       "<tr><td>6.58610098912506</td><td>8.000575487979999</td><td>[15.0,19.0,37.0,4...</td></tr>\n",
       "<tr><td>7.307916501843823</td><td>6.4374980503999994</td><td>[15.0,20.0,40.0,9...</td></tr>\n",
       "<tr><td>6.53890439878406</td><td>5.8753192823</td><td>[15.0,99.0,38.0,1...</td></tr>\n",
       "<tr><td>7.271971104022563</td><td>8.24969784404</td><td>[15.0,99.0,41.0,3...</td></tr>\n",
       "<tr><td>7.888608905619381</td><td>6.37576861704</td><td>[15.0,99.0,43.0,5...</td></tr>\n",
       "<tr><td>5.991988822721544</td><td>8.09316963802</td><td>[16.0,16.0,35.0,9...</td></tr>\n",
       "<tr><td>5.712223325739317</td><td>5.8135898489399995</td><td>[16.0,17.0,34.0,9...</td></tr>\n",
       "<tr><td>7.343353903431942</td><td>6.87401332916</td><td>[16.0,17.0,40.0,9...</td></tr>\n",
       "<tr><td>7.7032499285948335</td><td>9.25059651352</td><td>[16.0,17.0,41.0,5...</td></tr>\n",
       "<tr><td>7.1588151402125595</td><td>5.93704871566</td><td>[16.0,18.0,39.0,4...</td></tr>\n",
       "<tr><td>7.1588151402125595</td><td>6.56316153974</td><td>[16.0,18.0,39.0,4...</td></tr>\n",
       "<tr><td>7.0695816264852</td><td>6.75055446244</td><td>[16.0,18.0,39.0,9...</td></tr>\n",
       "<tr><td>6.270056292524166</td><td>4.9383546688</td><td>[16.0,19.0,36.0,1...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------------+------------------+--------------------+\n",
       "|        prediction|             label|            features|\n",
       "+------------------+------------------+--------------------+\n",
       "| 6.735331281174319|     6.25671899556|[13.0,17.0,38.0,6...|\n",
       "| 7.315888778823852| 8.437090766739999|[14.0,16.0,40.0,1...|\n",
       "| 7.372168136194236|     7.50012615324|[14.0,17.0,40.0,9...|\n",
       "|   6.7400855825755|     5.37486994756|[14.0,20.0,38.0,9...|\n",
       "| 5.682308546399798|      5.8753192823|[14.0,99.0,35.0,9...|\n",
       "|  4.33033463412318|3.0622208191799998|[15.0,18.0,29.0,9...|\n",
       "| 7.134663854645244|     9.06320359082|[15.0,18.0,39.0,3...|\n",
       "|  6.58610098912506| 8.000575487979999|[15.0,19.0,37.0,4...|\n",
       "| 7.307916501843823|6.4374980503999994|[15.0,20.0,40.0,9...|\n",
       "|  6.53890439878406|      5.8753192823|[15.0,99.0,38.0,1...|\n",
       "| 7.271971104022563|     8.24969784404|[15.0,99.0,41.0,3...|\n",
       "| 7.888608905619381|     6.37576861704|[15.0,99.0,43.0,5...|\n",
       "| 5.991988822721544|     8.09316963802|[16.0,16.0,35.0,9...|\n",
       "| 5.712223325739317|5.8135898489399995|[16.0,17.0,34.0,9...|\n",
       "| 7.343353903431942|     6.87401332916|[16.0,17.0,40.0,9...|\n",
       "|7.7032499285948335|     9.25059651352|[16.0,17.0,41.0,5...|\n",
       "|7.1588151402125595|     5.93704871566|[16.0,18.0,39.0,4...|\n",
       "|7.1588151402125595|     6.56316153974|[16.0,18.0,39.0,4...|\n",
       "|   7.0695816264852|     6.75055446244|[16.0,18.0,39.0,9...|\n",
       "| 6.270056292524166|      4.9383546688|[16.0,19.0,36.0,1...|\n",
       "+------------------+------------------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"prediction\", \"label\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select (prediction, true label) and compute test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.18882\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}