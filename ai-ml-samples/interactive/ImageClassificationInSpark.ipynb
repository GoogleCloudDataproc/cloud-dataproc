{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "With this notebook, we learn how to do distributed ML inference (image classification) using Dataproc Spark Serverless interactively.\n",
    "\n",
    "Following steps are performed:\n",
    "1. Create a [Vertex workbench](https://cloud.google.com/vertex-ai/docs/workbench/instances/create-dataproc-enabled) instance\n",
    "2. Connect to a remote-notebook using [serverless sessions](https://cloud.google.com/dataproc-serverless/docs/quickstarts/jupyterlab-sessions)\n",
    "3. Write code in the above notebook which runs on multiple Spark executors\n",
    "4. We then create a Spark DataFrame of the urls of the images we want to classify. We download a pre-trained Resnet50 model from  on driver, broadcast it to all the executors. Inference is written as a pandas UDF, that runs on each partition of the URLs.\n",
    "\n",
    "Note: You should first create a notebook mentioned in step 2 above, then import this entire notebook there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "## Notebook tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5303c05f7aa6"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fc324893334"
   },
   "outputs": [],
   "source": [
    "# All libraries needed in this notebook like torch, torchvision, google-cloud-storage are already installed in serverless. If you need something extra, feel free to do `pip install <library>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e43229f3ad4f"
   },
   "source": [
    "### List images to classify in a GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf93d5f0ce00"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "BUCKET_NAME = 'cloud-samples-data'\n",
    "bucket = client.get_bucket(BUCKET_NAME)\n",
    "\n",
    "# Limiting to only 50 images for sample\n",
    "blobs = bucket.list_blobs(prefix=\"generative-ai/image\", max_results=50)\n",
    "blobs = filter(lambda blob: get_blob_uri(blob).endswith(\"jpg\"), list(blobs))\n",
    "from google.cloud.storage.blob import Blob\n",
    "\n",
    "\n",
    "def get_blob_uri(blob):\n",
    "    return 'gs://' + blob.id[:-(len(str(blob.generation)) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "### Set Spark configurations, create Dataframe and broadcast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"classficationDemo\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Set to True for GPU enabled serverless sessions/dataproc clusters\n",
    "cuda = False\n",
    "\n",
    "# Enable Arrow support.\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"64\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader  # private API\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "\n",
    "use_cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "files_df = spark.createDataFrame(map(lambda file : get_blob_uri(file), blobs), StringType()).repartition(10)\n",
    "\n",
    "# Downloads and broadcasts the model weights to all the workers\n",
    "model_state = models.resnet50(pretrained=True).state_dict()\n",
    "bc_model_state = sc.broadcast(model_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrapper class and define Pandas UDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, index):\n",
    "        client = storage.Client()\n",
    "        path = self.paths[index]\n",
    "        blob = Blob.from_string(path, client=client)\n",
    "        local_file = \"/tmp/\" + path.split(\"/\")[-1]\n",
    "        blob.download_to_file(open(local_file, \"wb\"))\n",
    "        image = default_loader(local_file)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "def get_model_for_eval():\n",
    "    \"\"\"Gets the broadcasted model to each python worker\"\"\"\n",
    "    torch.hub.set_dir(\"/tmp/models\")\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.load_state_dict(bc_model_state.value)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Using Pandas UDF for parallel run on each partition\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def predict_batch_udf(paths: pd.Series) -> pd.Series:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    images = ImageDataset(paths, transform=transform)\n",
    "    loader = torch.utils.data.DataLoader(images, batch_size=500, num_workers=8)\n",
    "    model = get_model_for_eval()\n",
    "    model.to(device)\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            predictions = list(model(batch.to(device)).cpu().numpy())\n",
    "            for prediction in predictions:\n",
    "                all_predictions.append(prediction)\n",
    "    return pd.Series(all_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Call UDF on the DataFrame and write output to file, then read"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_file_path = \"/tmp/results\"\n",
    "predictions_df = files_df.select(col(\"value\"),\n",
    "                                 predict_batch_udf(col(\"value\"))).alias(\n",
    "    \"predictions\")\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)\n",
    "\n",
    "spark.read.parquet(output_file_path).limit(5).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
